{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b28a3c10-b963-4942-847e-c99265f8cc47",
   "metadata": {},
   "source": [
    "#### Copy paste keseluruhan text Pembukaan UUD 1945 dari website ini dari Judul sampai paragraf terakhir: https://raw.githubusercontent.com/nivdul/spark-in-practice-scala/refs/heads/master/data/wordcount.txt lalu save dengan nama wordcount.txt di local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d563bedb-60aa-478b-979a-4c94fb691cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/nivdul/spark-in-practice-scala/refs/heads/master/data/wordcount.txt\"\n",
    "\n",
    "# Download file\n",
    "response = requests.get(url)\n",
    "text_data = response.text\n",
    "\n",
    "# Save file into wordcount.txt\n",
    "with open(\"wordcount.txt\", \"w\") as file:\n",
    "    file.write(text_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc93cca-a8f3-4d89-9fdf-53558356bf8f",
   "metadata": {},
   "source": [
    "#### Install Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d78bc12-9705-409d-93bb-5548c443d6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mUnable to lock directory /var/lib/apt/lists/\u001b[0m\n",
      "\u001b[1;33mW: \u001b[0mProblem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\u001b[0m\n",
      "\u001b[1;33mW: \u001b[0mProblem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mCould not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\u001b[0m\n",
      "\u001b[1;31mE: \u001b[0mUnable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!apt update\n",
    "!apt install openjdk-8-jdk -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eee09f-c492-43fa-99a3-ee915d55c774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"/content/hadoop\"\n",
    "os.environ[\"PATH\"] += \":/content/hadoop/bin:/content/hadoop/sbin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c96cc4e-0138-4750-a421-0c45af99501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check hadoop version\n",
    "!hadoop version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5533ef3-63fb-49e2-bd30-b79506b146a5",
   "metadata": {},
   "source": [
    "#### Menjalankan MapReduce di Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077064b5-26a7-4a15-aa0f-7d8bee9b9595",
   "metadata": {},
   "source": [
    "#### Make new folder in HDFS and upload the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b305b-129e-48b7-8fff-c4ac16c1a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoop fs -mkdir -p /input\n",
    "hadoop fs -put wordcount.txt /input/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaedceb0-7346-43e5-8d6b-3a82087ffd27",
   "metadata": {},
   "source": [
    "#### Running Hadoop Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b53afa8-9dba-4327-9bbd-d25a1b78ba66",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hadoop jar /content/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.2.3.jar \\\n",
    "    -input /input/wordcount.txt \\\n",
    "    -output /output \\\n",
    "    -mapper \"python3 mapper.py\" \\\n",
    "    -reducer \"python3 reducer.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02408f78-3ec6-4f2e-b7be-168600f3c96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoop jar /path/to/hadoop-streaming-3.2.3.jar \\\n",
    "    -input /input/wordcount.txt \\\n",
    "    -output /output/wordcount_result \\\n",
    "    -mapper /path/to/mapper.py \\\n",
    "    -reducer /path/to/reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52393a6a-fa91-4705-ae2f-5f14c1cc713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoop fs -get /output/wordcount_result/part-00000 ./output_word_count.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
